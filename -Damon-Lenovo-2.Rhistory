})
dataInput2 <- reactive({
dataInput() %>%
filter(Station %in% input$station) %>%
pivot_longer(4:ncol(dataInput()),
names_to = "Variable", values_to = "Measure") %>%
filter(Variable == input$Variable)
})
dataInput3 <- reactive({
if(input$Time.res == "15 Min"){
dataInput2()
} else if(input$Time.res == "Hourly"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "hour"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()
} else if(input$Time.res == "Daily"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "day"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()
} else if(input$Time.res == "Weekly"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "week"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()}
})
## Plots -------------------------------------------------------------------
output$plot <- renderPlot({
p <- ggplot(dataInput3()) +
geom_line(aes(x = Timestamp, y = Measure, color = Station)) +
theme_bw() +
theme(axis.title.x = element_blank()) +
theme(axis.title.x = element_blank(),
axis.text.x = element_text(size = 20),
axis.title.y = element_text(size = 24),
axis.text.y = element_text(size = 20),
plot.title = element_text(size = 24)) +
ggtitle(str_c(input$tree, "_", input$Variable))
if(input$fixed.y == "Coarse"){
p <- p +
ylim(input$y.coarse[1], input$y.coarse[2])
}
if(input$fixed.y == "Fine"){
p <- p +
ylim(input$y.fine.min, input$y.fine.min + input$y.fine.range)
}
p
})
output$plot_clickinfo <- renderPrint({
val <- nearPoints(dataInput3(), input$plot_click, maxpoints = 1)
unique(val$Timestamp)
})
output$plot_brushedpoints <- renderPlot({
dat <- brushedPoints(dataInput3(), input$plot_brush)
if (nrow(dat) == 0)
return()
ggplot(dat) +
geom_line(aes(x = Timestamp, y = Measure)) +
theme_bw() +
theme(axis.title.x = element_blank()) +
theme(axis.title.x = element_blank(),
axis.text.x = element_text(size = 20),
axis.title.y = element_text(size = 24),
axis.text.y = element_text(size = 20),
plot.title = element_text(size = 24))
})
## Data and tables --------------------------------------------------------
output$max.date.out <- renderText({
as.character(max(dataInput3()$Timestamp, na.rm = T))
})
locate.datalogger <- reactive({
inst <- instruments %>%
filter(Variable == input$Variable) %>%
pull(Instrument)
zl6 %>%
filter(Location == input$tree & Station %in% input$station &
Instrument == inst) %>%
select(MC.ID) %>%
distinct()
})
output$wiring1 <- renderTable({
instruments %>%
filter(Variable == input$Variable)
})
output$wiring2 <- renderTable({
locate.datalogger()
})
output$wiring3 <- renderTable({
zl6 %>%
filter(Location == input$tree & MC.ID %in% locate.datalogger()$MC.ID) %>%
select(-ZL.ID, -Location) %>%
mutate(Port = as.numeric(Port))
})
output$wiring4 <- renderTable({
inst <- instruments %>%
filter(Variable == input$Variable) %>%
pull(Instrument)
instruments %>%
filter(Instrument == inst)
})
data.for.summaries <- reactive({
dataInput3() %>%
mutate(Timestamp = as.character(Timestamp))
})
output$data1 <- renderTable({
head(data.for.summaries())
})
output$data2 <- renderTable({
tail(data.for.summaries())
})
output$summary <- renderTable({
summarise_MC(data.for.summaries())
})
## Download options --------------------------------------------------------
data.for.download <- reactive({
if(input$All.variables == "All"){
dataInput()
} else {
dataInput3()
}
})
data.for.download2 <- reactive({
if(input$Time.format == "Excel_ready"){
data.for.download() %>%
mutate(Timestamp = as.character(Timestamp))
} else {
data.for.download()
}
})
output$downloadData <- downloadHandler(
filename = function() {
str_c(str_c(input$tree,
str_sub(as.character(input$daterange[1]), start = 1, end = 10),
str_sub(as.character(input$daterange[2]), start = 1, end = 10),
sep = "_"),
".csv")
},
content <-  function(file) {
write_csv(data.for.download2(), file)
}
)
}
shinyApp(ui, server)
zl6.noZC <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database.csv")) %>%
filter(Zentracloud == "No")
no.ZC.vec <- no.ZC.vec.full
# i <- no.ZC.vec[8]
for(i in no.ZC.vec){
filenames <- list.files(file.path("Microclimate_data_raw", "MC_noZC",
i),
pattern = "csv", full.names = T)
MC.ID <- str_split(i, "-")[[1]][1]
# Read true raw data and change column names
d <- lapply(filenames, read_MC_noZC) %>%
bind_rows() %>%
change_column_names(source = "NoZC") %>%
arrange(Timestamp)
# get rid of any ghost sensors
if(length(which(str_detect(names(d), "Unknown"))) > 0){
d2 <- d %>%
select(-names(d)[which(str_detect(names(d), "Unknown"))])
} else {
d2 <- d
}
d3 <- d2 %>%
mutate(Tree = str_split(MC.ID, "_")[[1]][1],
MC = str_split(MC.ID, "_")[[1]][2]) %>%
select(Tree, MC, Timestamp, everything())
write_csv(d3, file.path("Microclimate_data_raw", str_c(MC.ID, ".csv")))
cat("Imported from: ", MC.ID, "\n")
}
zl6.db.long <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database_long.csv"))
zl6.db <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database.csv"))
moved.instruments <- read_excel(file.path("Microclimate_data_supporting",
"zl6_moved_instruments.xlsx")) %>%
select(Tree, Station, Instrument, MC.old, MC.new, Timestamp) %>%
pivot_longer(4:5, names_to = "Tracking", values_to = "MC")
tree.vec <- full.tree.vec
# i <- "FB6"
for(i in tree.vec){
d.nst <- MC_to_tree(i)
d.nst2 <- d.nst %>%
mutate(data = map(data, fix_duplicate_timestamps))
# Moving instrument to new datalogger causes a duplicated record with filler NAs
suppressMessages(dupe.check <- d.nst2 %>%
select(-data) %>%
group_by(Tree, Station, Instrument) %>%
summarise(count = length(Station)) %>%
filter(count != 1))
if(nrow(dupe.check != 0)){
d.nst3 <- fix_moved_sensors(d.nst2)
} else {
d.nst3 <- d.nst2
}
stations <- unique(d.nst3$Station)
d.list <- lapply(stations, MC_to_station, d.nested = d.nst3)
d.list2 <- lapply(d.list, remove_station_from_header)
d <- d.list2 %>%
bind_rows() %>%
select(-ATM22_temp, -ATM22_Xaxis,
-ATM22_Yaxis) %>%
arrange(Tree, Station, Timestamp)
# Drop VPD because it doesn't come in every tree
if("VPD" %in% colnames(d)){
d2 <- d %>%
select(-VPD)
} else {
d2 <- d
}
# Get rid of LW_Minutes so it looks like the preJune. Maintain LW_Minutes_H
d3 <- d2 %>%
mutate(Wetness = 1.54 * exp(0.0058 * LWS_Count)) %>%
select(-LWS_Count, -LW_minutes)
write_csv(d3, file.path("Microclimate_data_L2",
str_c(i, "_MC", "_L2.csv")))
cat("saved data for: ", i, "\n")
}
pasture.vec <- full.ground.vec
# i <- "TVP"
for(i in pasture.vec){
d <- read_csv(file.path("Microclimate_data_raw", str_c(i, "_ATM41.csv"))) %>%
mutate(Station = "S0") %>%
select(-MC) %>%
select(Tree, Station, Timestamp, everything()) %>%
remove_port_from_header() %>%
mutate(Wetness = 1.54 * exp(0.0058 * LWS_Count))
d2 <- d %>%
select(-Lightning_count, -Lightning_distance, -ATM22_Yaxis,
-ATM22_Xaxis, -ATM41_SensorTemp,
-Drop1, -Drop2, -Drop3, -Drop4,
-LWS_Count, -LW_minutes)
d3 <- fix_duplicate_timestamps(d2)
write_csv(d3, file.path("Microclimate_data_L2",
str_c(i, "_MC", "_L2.csv")))
cat("saved data for: ", i, "\n")
}
library(needs)
needs(tidyverse, lubridate)
tree.vec <- full.tree.vec
pasture.vec <- full.ground.vec
MC.vec <- c(tree.vec, pasture.vec)
# i <- "FB6"
for(i in MC.vec){
old.dat <- read_csv(file.path("Microclimate_data_L2",
"Microclimate_toJune2023_L2",
str_c(i, "_LVL2.csv"))) %>%
select(-VPD)
if(i %in% pasture.vec){
old.dat2 <- old.dat %>%
rename(Tree = PastureID) %>%
mutate(Station = "S0") %>%
select(Tree, Station, Timestamp, everything())
} else{
old.dat2 <- old.dat
}
old.dat3 <- old.dat2 %>%
group_by(Station) %>%
nest() %>%
mutate(data = map(data, fix_duplicate_timestamps)) %>%
unnest(data) %>%
ungroup()
filename.in.L2 <- file.path("Microclimate_data_L2",
str_c(i, "_MC", "_L2.csv"))
if(file.exists(filename.in.L2)){
new.dat <- read_csv(file.path("Microclimate_data_L2",
str_c(i, "_MC_L2.csv")))
old.dat4 <- old.dat3 %>%
filter(Timestamp < min(new.dat$Timestamp, na.rm = T))
d <- bind_rows(old.dat4, new.dat)
} else {
d <- old.dat3
cat("no new data for: ", i, "\n")
}
d2 <- d %>%
distinct() %>%
arrange(Tree, Station, Timestamp)
write_csv(d2, file.path("Microclimate_data_L3",
str_c(i, "_MC", "_L3.csv")))
cat("saved data for: ", i, "\n")
}
shinyApp(ui, server)
library(needs)
needs(tidyverse, readxl)
source("3_Functions_Microclimate.R")
options(readr.show_col_types = FALSE)
theme_set(theme_bw())
RH.low.maxes.global <- c("ET2_S4", "ET7_S4", "FB4_S1", "FB4_S4", "TV3_S2")
RH.low.maxes.local <- c("FB8_S5")
bad.data <- read_excel(file.path("Microclimate_data_supporting", "MC_bad_data_windows_Damon.xlsx")) %>%
select(-Note)
bad.data.nst <- bad.data %>%
group_by(Tree, Station, Variable) %>%
nest() %>%
mutate(Data.expanded = map(data, expand_data_window, "15 min")) %>%
select(-data)
bad.data.expanded <- bad.data.nst  %>%
unnest(Data.expanded) %>%
ungroup() %>%
rename(Bad.data = Data.flag)
# i <- "FB8"
tree.vec <- full.tree.vec
ground.vec <- full.ground.vec
MC.vec <- c(tree.vec, ground.vec)
# MC.vec <- "FBP2"
# !!!! SLOW !!!!!
for(i in MC.vec){
d <- read_csv(file.path("Microclimate_data_L3", str_c(i, "_MC", "_L3.csv")))
## Remove bad data ---------------------------------------------------------
BDE <- bad.data.expanded %>%
filter(Tree == i)
d2 <- d %>%
pivot_longer(4:12, names_to = "Variable", values_to = "Value") %>%
left_join(BDE, by = c("Tree", "Station", "Variable", "Timestamp")) %>%
mutate(Value = ifelse(!is.na(Bad.data), NA, Value)) %>%
select(-Bad.data) %>%
pivot_wider(names_from = Variable, values_from = Value)
# These thresholds are determined in the lower section of the script
d3 <- d2 %>%
mutate(Temp = ifelse(Temp == 0, NA, Temp),
RH = ifelse(RH == 0, NA, RH),
Atmos_pressure = ifelse(Atmos_pressure == 0, NA, Atmos_pressure),
Atmos_pressure = ifelse(Atmos_pressure > 100, NA, Atmos_pressure),
Wetness = ifelse(Wetness > 2500, NA, Wetness))
# RH fixes ------------------------------------------------------------------
# Change all RH > 1 to 1, then nest the df for the adjustment functions
d3.nst <- d3 %>%
mutate(RH = ifelse(RH > 1, 1, RH)) %>%
mutate(Key = str_c(i, "_", Station)) %>%
group_by(Station) %>%
nest()
d4 <- d3.nst %>%
mutate(data = map(data, adjust_RH_maxes_global)) %>%
mutate(data = map(data, adjust_RH_maxes_local)) %>%
unnest(data) %>%
ungroup() %>%
select(-Key)
# Calculate variables -----------------------------------------------------
d5 <- d4 %>%
mutate(VPD = calculate_VPD(Temp, RH))
# Save --------------------------------------------------------------------
write_csv(d5, file.path("Microclimate_data_L4",
str_c(i, "_MC", "_L4.csv")))
cat("saved data for: ", i, "\n")
}
shinyApp(ui, server)
library(needs)
needs(tidyverse, zentracloud, readxl)
source("3_Functions_Microclimate.R")
options(readr.show_col_types = FALSE)
# Laptop
setZentracloudOptions(
cache_dir = "C:/Users/vaug8/AppData/Local/R/cache/R/zentracloud",
token = "2f197f0980ac6da7c6bc2922f48f6ac291ca1086"
, domain = "default"
)
endDL <- "2024-06-30 23:23:59"
Log <- data.frame(MC = NA, Action = NA, Reason = NA)
MC.vec <- c("ET7_MC1")
# MC.vec <- c("ET7_MC1")
# i <- "ET2_MC1"
for(i in MC.vec){
# Have to read and write this for each element
import.log <- read_csv(file.path("Microclimate_data_supporting",
"zl6_import_log.csv"), show_col_types = F)
#  Check timestamp of last import
Last.import <- import.log %>%
filter(MC.ID == i) %>%
pull(Last.import)
# Verify > 3 day difference between the import log and endDL timestamp. If satisfied, download from last import to endDL. If not, skip to next and note in the log
if(Last.import <= as.POSIXct(endDL) - days(3)) {
repeat {
tryCatch({
# subtract 5 hours to fix strange gap before data start
MC <- read_ZC(i, as.character(Last.import - hours(5)), endDL)
# MC <- read_ZC(i, Start = "2023-06-01 00:00:00",
#               End = "2023-06-08 00:00:00")
break
}
, error = function(e) {
# An error occurred, so print a message and continue with the same i
cat(paste("Error on iteration", i, ":", conditionMessage(e), "\n"))
}
)
}
} else {
cat("Skipped ", i, ", no import needed", "\n")
Log1 <- data.frame(MC = i, Action = "Skipped",
Reason = "Import log")
Log <- bind_rows(Log, Log1)
next
}
# Format each port's data and combine them together. reduce function is a way to join list elements by a key column
d <- lapply(seq(1:length(MC)), format_element) %>%
lapply(change_column_names, "ZC_R") %>%
reduce(left_join, by = "Timestamp")
# Extract metadata from i
MC.ID <- str_c(str_sub(i, start = 5, end = 7))
Tree.ID <- str_sub(i, start = 1, end = 3)
# Add metadata to the df and sort columns
d2 <- d %>%
# rename_with(.cols = !starts_with("Time"), .fn = ~str_c(MC.ID, .)) %>%
mutate(Tree = Tree.ID,
MC = MC.ID) %>%
select(Tree, MC, Timestamp, everything())
filename.in.raw <- file.path("Microclimate_data_raw", str_c(i, ".csv"))
if(file.exists(filename.in.raw)){
raw.data <- read_csv(filename.in.raw, show_col_types = F)
d.out <- bind_rows(raw.data, d2) %>%
distinct() %>%
arrange(Timestamp)
write_csv(d.out, filename.in.raw)
} else{
write_csv(d2, filename.in.raw)
}
cat("Finished ", i, "\n")
import.log <- import.log %>%
mutate(Last.import = case_when(
MC.ID == i ~ max(d2$Timestamp, na.rm = T),
MC.ID != i ~ Last.import))
Log1 <- data.frame(MC = i, Action = "Saved raw data",
Problems = "None")
Log <- bind_rows(Log, Log1)
write_csv(import.log, file.path("Microclimate_data_supporting",
"zl6_import_log.csv"))
}
tree.vec <- "ET7"
# tree.vec <- "ET7"
for(i in tree.vec){
d.nst <- MC_to_tree(i)
d.nst2 <- d.nst %>%
mutate(data = map(data, fix_duplicate_timestamps))
# Moving instrument to new datalogger causes a duplicated record with filler NAs
suppressMessages(dupe.check <- d.nst2 %>%
select(-data) %>%
group_by(Tree, Station, Instrument) %>%
summarise(count = length(Station)) %>%
filter(count != 1))
if(nrow(dupe.check != 0)){
d.nst3 <- fix_moved_sensors(d.nst2)
} else {
d.nst3 <- d.nst2
}
stations <- unique(d.nst3$Station)
d.list <- lapply(stations, MC_to_station, d.nested = d.nst3)
d.list2 <- lapply(d.list, remove_station_from_header)
d <- d.list2 %>%
bind_rows() %>%
select(-ATM22_temp, -ATM22_Xaxis,
-ATM22_Yaxis) %>%
arrange(Tree, Station, Timestamp)
# Drop VPD because it doesn't come in every tree
if("VPD" %in% colnames(d)){
d2 <- d %>%
select(-VPD)
} else {
d2 <- d
}
# Get rid of LW_Minutes so it looks like the preJune. Maintain LW_Minutes_H
d3 <- d2 %>%
mutate(Wetness = 1.54 * exp(0.0058 * LWS_Count)) %>%
select(-LWS_Count, -LW_minutes)
write_csv(d3, file.path("Microclimate_data_L2",
str_c(i, "_MC", "_L2.csv")))
cat("saved data for: ", i, "\n")
}
library(needs)
needs(tidyverse, lubridate)
MC.vec <- "ET7"
# MC.vec <- "ET7"
for(i in MC.vec){
old.dat <- read_csv(file.path("Microclimate_data_L2",
"Microclimate_toJune2023_L2",
str_c(i, "_LVL2.csv"))) %>%
select(-VPD)
if(i %in% pasture.vec){
old.dat2 <- old.dat %>%
rename(Tree = PastureID) %>%
mutate(Station = "S0") %>%
select(Tree, Station, Timestamp, everything())
} else{
old.dat2 <- old.dat
}
old.dat3 <- old.dat2 %>%
group_by(Station) %>%
nest() %>%
mutate(data = map(data, fix_duplicate_timestamps)) %>%
unnest(data) %>%
ungroup()
filename.in.L2 <- file.path("Microclimate_data_L2",
str_c(i, "_MC", "_L2.csv"))
if(file.exists(filename.in.L2)){
new.dat <- read_csv(file.path("Microclimate_data_L2",
str_c(i, "_MC_L2.csv")))
old.dat4 <- old.dat3 %>%
filter(Timestamp < min(new.dat$Timestamp, na.rm = T))
d <- bind_rows(old.dat4, new.dat)
} else {
d <- old.dat3
cat("no new data for: ", i, "\n")
}
d2 <- d %>%
distinct() %>%
arrange(Tree, Station, Timestamp)
write_csv(d2, file.path("Microclimate_data_L3",
str_c(i, "_MC", "_L3.csv")))
cat("saved data for: ", i, "\n")
}
shinyApp(ui, server)
