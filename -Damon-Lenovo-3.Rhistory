brush = "plot_brush"),
verbatimTextOutput("plot_clickinfo"),
plotOutput("plot_brushedpoints")),
tabPanel("Wiring", tableOutput("wiring1"), tableOutput("wiring2"),
tableOutput("wiring3"), tableOutput("wiring4")),
tabPanel("Data", tableOutput("data1"), tableOutput("data2")),
tabPanel("Summary", tableOutput("summary"))))
)
)
server <- function(input, output, session) {
dataInput <- reactive({
read_csv(file.path(str_c("Microclimate_data_", input$Level),
str_c(input$tree, "_MC_", input$Level, ".csv"))) %>%
filter(Tree == input$tree) %>%
filter(Timestamp >= as.POSIXct(input$daterange[1], tz = "UTC")  &
Timestamp <= as.POSIXct(input$daterange[2], tz = "UTC"))
})
dataInput2 <- reactive({
dataInput() %>%
filter(Station %in% input$station) %>%
pivot_longer(4:ncol(dataInput()),
names_to = "Variable", values_to = "Measure") %>%
filter(Variable == input$Variable)
})
dataInput3 <- reactive({
if(input$Time.res == "15 Min"){
dataInput2()
} else if(input$Time.res == "Hourly"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "hour"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()
} else if(input$Time.res == "Daily"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "day"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()
} else if(input$Time.res == "Weekly"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "week"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()}
})
## Plots -------------------------------------------------------------------
output$plot <- renderPlot({
p <- ggplot(dataInput3()) +
geom_line(aes(x = Timestamp, y = Measure, color = Station)) +
theme_bw() +
theme(axis.title.x = element_blank()) +
theme(axis.title.x = element_blank(),
axis.text.x = element_text(size = 20),
axis.title.y = element_text(size = 24),
axis.text.y = element_text(size = 20),
plot.title = element_text(size = 24)) +
ggtitle(str_c(input$tree, "_", input$Variable))
if(input$fixed.y == "Coarse"){
p <- p +
ylim(input$y.coarse[1], input$y.coarse[2])
}
if(input$fixed.y == "Fine"){
p <- p +
ylim(input$y.fine.min, input$y.fine.min + input$y.fine.range)
}
p
})
output$plot_clickinfo <- renderPrint({
val <- nearPoints(dataInput3(), input$plot_click, maxpoints = 1)
unique(val$Timestamp)
})
output$plot_brushedpoints <- renderPlot({
dat <- brushedPoints(dataInput3(), input$plot_brush)
if (nrow(dat) == 0)
return()
ggplot(dat) +
geom_line(aes(x = Timestamp, y = Measure)) +
theme_bw() +
theme(axis.title.x = element_blank()) +
theme(axis.title.x = element_blank(),
axis.text.x = element_text(size = 20),
axis.title.y = element_text(size = 24),
axis.text.y = element_text(size = 20),
plot.title = element_text(size = 24))
})
## Data and tables --------------------------------------------------------
output$max.date.out <- renderText({
as.character(max(dataInput3()$Timestamp, na.rm = T))
})
locate.datalogger <- reactive({
inst <- instruments %>%
filter(Variable == input$Variable) %>%
pull(Instrument)
zl6 %>%
filter(Location == input$tree & Station %in% input$station &
Instrument == inst) %>%
select(MC.ID) %>%
distinct()
})
output$wiring1 <- renderTable({
instruments %>%
filter(Variable == input$Variable)
})
output$wiring2 <- renderTable({
locate.datalogger()
})
output$wiring3 <- renderTable({
zl6 %>%
filter(Location == input$tree & MC.ID %in% locate.datalogger()$MC.ID) %>%
select(-ZL.ID, -Location) %>%
mutate(Port = as.numeric(Port))
})
output$wiring4 <- renderTable({
inst <- instruments %>%
filter(Variable == input$Variable) %>%
pull(Instrument)
instruments %>%
filter(Instrument == inst)
})
data.for.summaries <- reactive({
dataInput3() %>%
mutate(Timestamp = as.character(Timestamp))
})
output$data1 <- renderTable({
head(data.for.summaries())
})
output$data2 <- renderTable({
tail(data.for.summaries())
})
output$summary <- renderTable({
summarise_MC(data.for.summaries())
})
## Download options --------------------------------------------------------
data.for.download <- reactive({
if(input$All.variables == "All"){
dataInput()
} else {
dataInput3()
}
})
data.for.download2 <- reactive({
if(input$Time.format == "Excel_ready"){
data.for.download() %>%
mutate(Timestamp = as.character(Timestamp))
} else {
data.for.download()
}
})
output$downloadData <- downloadHandler(
filename = function() {
str_c(str_c(input$tree,
str_sub(as.character(input$daterange[1]), start = 1, end = 10),
str_sub(as.character(input$daterange[2]), start = 1, end = 10),
sep = "_"),
".csv")
},
content <-  function(file) {
write_csv(data.for.download2(), file)
}
)
}
shinyApp(ui, server)
shinyApp(ui, server)
library(needs)
needs(tidyverse, zentracloud, readxl)
source("3_Functions_Microclimate.R")
source("1_Functions_Microclimate.R")
source("1_Functions_Microclimate.R")
source("1_Functions_Microclimate.R")
source("1_Functions_Microclimate.R")
options(readr.show_col_types = FALSE)
zl6.db <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database.csv")) %>%
filter(Zentracloud == "Yes")
name.change <- read_excel(file.path("Microclimate_data_supporting",
"Variable_names.xlsx"))
import.log <- read_csv(file.path("Microclimate_data_supporting",
"zl6_import_log.csv"), show_col_types = F)
zl6.noZC <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database.csv")) %>%
filter(Zentracloud == "No")
library(needs)
needs(tidyverse, readxl)
source("1_Functions_Microclimate.R")
options(readr.show_col_types = FALSE)
zl6.db.long <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database_long.csv"))
zl6.db <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database.csv"))
moved.instruments <- read_excel(file.path("Microclimate_data_supporting",
"zl6_moved_instruments.xlsx")) %>%
select(Tree, Station, Instrument, MC.old, MC.new, Timestamp) %>%
pivot_longer(4:5, names_to = "Tracking", values_to = "MC")
# tree.vec <- "ET7"
i <- "ET5"
d.nst <- MC_to_tree(i)
# MC_to_port extracts data from an individual port and saves as nested dataframe that also holds the metadata about station number and instrument type
# Parameters. Portnum: Port number, typically passed in from the MC_to_datalogger function; df: raw data, also typically passed in from that function
# Portnum <- 6
df <- read_csv(file.path("Microclimate_data_raw", str_c("FB1_MC1", ".csv")),
show_col_types = F)
# MC_to_port extracts data from an individual port and saves as nested dataframe that also holds the metadata about station number and instrument type
# Parameters. Portnum: Port number, typically passed in from the MC_to_datalogger function; df: raw data, also typically passed in from that function
Portnum <- 6
MCID <- unique(df$MC)
TreeID <- unique(df$Tree)
port.metadata = zl6.db.long %>%
filter(MC.ID == str_c(TreeID, "_", MCID)) %>%
filter(Port == Portnum)
View(port.metadata)
View(df)
df2 <- df %>%
select(Tree, MC, Timestamp,
which(str_detect(colnames(df),
str_c("Port", as.character(Portnum))) == T)) %>%
mutate(Station = pull(port.metadata, Station)) %>%
mutate(Instrument = pull(port.metadata, Instrument)) %>%
select(Tree, MC, Station, Instrument, Timestamp, everything()) %>%
rename_with(swap_port_for_station)
# Swap Port # for Station #. Need to keep some identifier to avoid column name duplication, but this accounts for sensors being moved to different ports
swap_port_for_station <- function(x){
str_replace(x, "Port\\d+", pull(port.metadata, Station))
}
df2 <- df %>%
select(Tree, MC, Timestamp,
which(str_detect(colnames(df),
str_c("Port", as.character(Portnum))) == T)) %>%
mutate(Station = pull(port.metadata, Station)) %>%
mutate(Instrument = pull(port.metadata, Instrument)) %>%
select(Tree, MC, Station, Instrument, Timestamp, everything()) %>%
rename_with(swap_port_for_station)
View(df)
View(df2)
MC_to_port(6, df)
MC_to_port(5, df)
test <- MC_to_port(5, df)
View(test)
View(test[[5]][[1]])
View(zl6.db)
View(zl6.db.long)
# MC_to_datalogger reads the raw data from a datalogger, and applies MC_to_port to all ports and creates a nested dataframe that carries the port metadata
# Parameters. MCnum: MCID of an individual datalogger (eg "FB1_MC1), typically passed in from MC_to_tree
MCnum <- "ET5_MC3"
rawdat <- read_csv(file.path("Microclimate_data_raw", str_c(MCnum, ".csv")),
show_col_types = F)
View(rawdat)
# make vector of active port numbers
port.vec <- zl6.db.long %>%
filter(MC.ID == MCnum) %>%
select(MC.ID, Port, Station) %>%
na.omit()
View(port.vec)
MC_to_datalogger("ET5_MC3")
MC_to_datalogger("ET5_MC2")
MC_to_datalogger("ET5_MC1")
MC_to_datalogger("ET5_MC3")
# MC_to_port extracts data from an individual port and saves as 1 row in a nested dataframe that also holds the metadata about station number and instrument type. ***This is the function that really does the work here; the other two are just organizing the outputs from this one.
# Parameters. Portnum: Port number, typically passed in from the MC_to_datalogger function; df: raw data, also typically passed in from that function
Portnum <- 6
df <- read_csv(file.path("Microclimate_data_raw", str_c("FB1_MC1", ".csv")),
MCID <- unique(df$MC)
# MC_to_port extracts data from an individual port and saves as 1 row in a nested dataframe that also holds the metadata about station number and instrument type. ***This is the function that really does the work here; the other two are just organizing the outputs from this one.
# Parameters. Portnum: Port number, typically passed in from the MC_to_datalogger function; df: raw data, also typically passed in from that function
Portnum <- 6
df <- read_csv(file.path("Microclimate_data_raw", str_c("FB1_MC1", ".csv")),
show_col_types = F)
MCID <- unique(df$MC)
TreeID <- unique(df$Tree)
port.metadata = zl6.db.long %>%
filter(MC.ID == str_c(TreeID, "_", MCID)) %>%
filter(Port == Portnum)
# Swap Port # for Station #. Need to keep some identifier to avoid column name duplication, but this accounts for sensors being moved to different ports
swap_port_for_station <- function(x){
str_replace(x, "Port\\d+", pull(port.metadata, Station))
}
df2 <- df %>%
select(Tree, MC, Timestamp,
which(str_detect(colnames(df),
str_c("Port", as.character(Portnum))) == T)) %>%
mutate(Station = pull(port.metadata, Station)) %>%
mutate(Instrument = pull(port.metadata, Instrument)) %>%
select(Tree, MC, Station, Instrument, Timestamp, everything()) %>%
rename_with(swap_port_for_station)
View(df2)
df3 <- df2  %>%
group_by(Tree, MC, Station, Instrument) %>%
nest() %>%
mutate(Start.timestamp = min(df2$Timestamp, na.rm = T),
End.timestamp = max(df2$Timestamp, na.rm = T))
View(df3)
# MC_to_tree applies MC_to_datalogger to all dataloggers in a tree and binds the results together
# Parameters. TreeID: Name of a tree
# TreeID <- "TV1"
MC_to_tree <- function(TreeID){
ZLs <- zl6.db %>%
filter(Location == TreeID) %>%
pull(MC.ID)
d <- lapply(ZLs, MC_to_datalogger) %>%
bind_rows()
return(d)
}
test <- MC_to_tree("ET5")
View(test)
MC_to_datalogger <- function(MCnum){
rawdat <- read_csv(file.path("Microclimate_data_raw", str_c(MCnum, ".csv")),
show_col_types = F)
# make vector of active port numbers
port.vec <- zl6.db.long %>%
filter(MC.ID == MCnum) %>%
select(MC.ID, Port, Station) %>%
na.omit()
lapply(port.vec$Port, MC_to_port, df = rawdat) %>%
bind_rows()
}
MC_to_datalogger("ET5_MC3")
MC_to_port <- function(Portnum, df){
MCID <- unique(df$MC)
TreeID <- unique(df$Tree)
port.metadata = zl6.db.long %>%
filter(MC.ID == str_c(TreeID, "_", MCID)) %>%
filter(Port == Portnum)
# Swap Port # for Station #. Need to keep some identifier to avoid column name duplication, but this accounts for sensors being moved to different ports
swap_port_for_station <- function(x){
str_replace(x, "Port\\d+", pull(port.metadata, Station))
}
df2 <- df %>%
select(Tree, MC, Timestamp,
which(str_detect(colnames(df),
str_c("Port", as.character(Portnum))) == T)) %>%
mutate(Station = pull(port.metadata, Station)) %>%
mutate(Instrument = pull(port.metadata, Instrument)) %>%
select(Tree, MC, Station, Instrument, Timestamp, everything()) %>%
rename_with(swap_port_for_station)
df3 <- df2  %>%
group_by(Tree, MC, Station, Instrument) %>%
nest() %>%
mutate(Start.timestamp = min(df2$Timestamp, na.rm = T),
End.timestamp = max(df2$Timestamp, na.rm = T))
return(df3)
}
MC_to_datalogger("ET5_MC3")
test <- MC_to_tree("ET5")
MC_to_port <- function(Portnum, df){
MCID <- unique(df$MC)
TreeID <- unique(df$Tree)
port.metadata = zl6.db.long %>%
filter(MC.ID == str_c(TreeID, "_", MCID)) %>%
filter(Port == Portnum)
# Swap Port # for Station #. Need to keep some identifier to avoid column name duplication, but this accounts for sensors being moved to different ports
swap_port_for_station <- function(x){
str_replace(x, "Port\\d+", pull(port.metadata, Station))
}
df2 <- df %>%
select(Tree, MC, Timestamp,
which(str_detect(colnames(df),
str_c("Port", as.character(Portnum))) == T)) %>%
mutate(Station = pull(port.metadata, Station)) %>%
mutate(Instrument = pull(port.metadata, Instrument)) %>%
select(Tree, MC, Station, Instrument, Timestamp, everything()) %>%
rename_with(swap_port_for_station)
df3 <- df2  %>%
group_by(Tree, MC, Station, Instrument) %>%
nest()
# %>%
#   mutate(Start.timestamp = min(df2$Timestamp, na.rm = T),
#          End.timestamp = max(df2$Timestamp, na.rm = T))
return(df3)
}
MC_to_datalogger("ET5_MC3")
library(needs)
needs(tidyverse, readxl)
source("1_Functions_Microclimate.R")
source("Functions_new_test.R")
options(readr.show_col_types = FALSE)
zl6.db.long <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database_long.csv"))
zl6.db <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database.csv"))
moved.instruments <- read_excel(file.path("Microclimate_data_supporting",
"zl6_moved_instruments.xlsx")) %>%
select(Tree, Station, Instrument, MC.old, MC.new, Timestamp) %>%
pivot_longer(4:5, names_to = "Tracking", values_to = "MC")
# tree.vec <- "ET7"
i <- "ET5"
d.nst <- MC_to_tree(i)
d.nst2 <- d.nst %>%
mutate(data = map(data, fix_duplicate_timestamps))
# fix_duplicate_timestamps fixes the duplicate timestamps that come from ZentraCloud. Sometimes multiple records are given of the same timestamp, which can cause major problems with joins. This is a quick and dirty method that just grabs the last entry. Meant to work on a single time series at a time, so must nest first if working at tree or higher levels.
# Parameters. x: a dataframe, typically one unnested row from MC_to_tree
d.nst <- MC_to_tree("ET3") %>%
filter(Station == "S5")
View(d.nst)
# fix_duplicate_timestamps fixes the duplicate timestamps that come from ZentraCloud. Sometimes multiple records are given of the same timestamp, which can cause major problems with joins. This is a quick and dirty method that just grabs the last entry. Meant to work on a single time series at a time, so must nest first if working at tree or higher levels.
# Parameters. x: a dataframe, typically one unnested row from MC_to_tree
d.nst <- MC_to_tree("ET3") %>%
filter(Station == "S5") %>%
filter(Instrument == "A14")
# fix_duplicate_timestamps fixes the duplicate timestamps that come from ZentraCloud. Sometimes multiple records are given of the same timestamp, which can cause major problems with joins. This is a quick and dirty method that just grabs the last entry. Meant to work on a single time series at a time, so must nest first if working at tree or higher levels.
# Parameters. x: a dataframe, typically one unnested row from MC_to_tree
d.nst <- MC_to_tree("ET3") %>%
filter(Station == "S5") %>%
filter(Instrument == "A14") %>%
unnest(data)
View(d.nst)
duplicated(d.nst$Timestamp)
which(duplicated(d.nst$Timestamp) == T)
# fix_duplicate_timestamps fixes the duplicate timestamps that come from ZentraCloud. Sometimes multiple records are given of the same timestamp, which can cause major problems with joins. This is a quick and dirty method that just grabs the last entry. Meant to work on a single time series at a time, so must nest first if working at tree or higher levels.
# Parameters. x: a dataframe, typically one unnested row from MC_to_tree
d <- MC_to_tree("ET3") %>%
filter(Station == "S5") %>%
filter(Instrument == "A14") %>%
unnest(data)
# fix_duplicate_timestamps fixes the duplicate timestamps that come from ZentraCloud. Sometimes multiple records are given of the same timestamp, which can cause major problems with joins. This is a quick and dirty method that just grabs the last entry. Meant to work on a single time series at a time, so must nest first if working at tree or higher levels.
# Parameters. x: a dataframe, typically one unnested row from MC_to_tree
x <- MC_to_tree("ET3") %>%
filter(Station == "S5") %>%
filter(Instrument == "A14") %>%
unnest(data)
which(duplicated(x$Timestamp) == T)
x2 <- x %>%
distinct() %>%
arrange(Timestamp)
which(duplicated(x2$Timestamp) == T)
# Create df with all but the first entry. In first entry, Timestamp does not equal the previous timestamp, but in all others it does. This df will be removed from x2
dupe.time <- x2  %>%
mutate(Timestamp2 = lag(Timestamp)) %>%
filter(Timestamp == Timestamp2)
View(dupe.time)
fix_ZC_timestamp_duplication <- function(x){
x2 <- x %>%
distinct() %>%
arrange(Timestamp)
# Create df with all but the first entry. In first entry, Timestamp does not equal the previous timestamp, but in all others it does. This df will be removed from x2
dupe.time <- x2  %>%
mutate(Timestamp2 = lag(Timestamp)) %>%
filter(Timestamp == Timestamp2)
# anti join means that all entries in dupe.time will be removed, leaving only the first
suppressMessages(x3 <- x2 %>%
anti_join(dupe.time))
return(x3)
}
test <- fix_ZC_timestamp_duplication(x)
which(duplicated(test$Timestamp) == T)
test <- MCdata_to_tree("ET5")
# MCdata_to_tree applies MCdata_to_datalogger to all dataloggers in a tree and binds the results together
# Parameters. TreeID: Name of a tree
# TreeID <- "TV1"
MCdata_to_tree <- function(TreeID){
ZLs <- zl6.db %>%
filter(Location == TreeID) %>%
pull(MC.ID)
d <- lapply(ZLs, MCdata_to_datalogger) %>%
bind_rows()
return(d)
}
MCdata_to_datalogger <- function(MCnum){
rawdat <- read_csv(file.path("Microclimate_data_raw", str_c(MCnum, ".csv")),
show_col_types = F)
# make vector of active port numbers
port.vec <- zl6.db.long %>%
filter(MC.ID == MCnum) %>%
select(MC.ID, Port, Station) %>%
na.omit()
lapply(port.vec$Port, MCdata_to_port, df = rawdat) %>%
bind_rows()
}
MCdata_to_port <- function(Portnum, df){
MCID <- unique(df$MC)
TreeID <- unique(df$Tree)
port.metadata = zl6.db.long %>%
filter(MC.ID == str_c(TreeID, "_", MCID)) %>%
filter(Port == Portnum)
# Swap Port # for Station #. Need to keep some identifier to avoid column name duplication, but this accounts for sensors being moved to different ports
swap_port_for_station <- function(x){
str_replace(x, "Port\\d+", pull(port.metadata, Station))
}
df2 <- df %>%
select(Tree, MC, Timestamp,
which(str_detect(colnames(df),
str_c("Port", as.character(Portnum))) == T)) %>%
mutate(Station = pull(port.metadata, Station)) %>%
mutate(Instrument = pull(port.metadata, Instrument)) %>%
select(Tree, MC, Station, Instrument, Timestamp, everything()) %>%
rename_with(swap_port_for_station)
df3 <- df2  %>%
group_by(Tree, MC, Station, Instrument) %>%
nest()
# %>%
#   mutate(Start.timestamp = min(df2$Timestamp, na.rm = T),
#          End.timestamp = max(df2$Timestamp, na.rm = T))
return(df3)
}
test <- MCdata_to_tree("ET5")
# fix_ZC_timestamp_duplication fixes the duplicate timestamps that come from ZentraCloud. Sometimes multiple records are given of the same timestamp, which can cause major problems with joins. This is a quick and dirty method that just grabs the last entry. Meant to work on a single time series at a time, so must nest first if working at tree or higher levels.
# Parameters. df: a dataframe, typically one unnested row from MC_to_tree
df <- MC_to_tree("ET3") %>%
filter(Station == "S5") %>%
filter(Instrument == "A14") %>%
unnest(data)
which(duplicated(df$Timestamp) == T)
fix_ZC_timestamp_duplication <- function(df){
x2 <- df %>%
distinct() %>%
arrange(Timestamp)
# Create df with all but the first entry. In first entry, Timestamp does not equal the previous timestamp, but in all others it does. This df will be removed from x2
dupe.time <- x2  %>%
mutate(Timestamp2 = lag(Timestamp)) %>%
filter(Timestamp == Timestamp2)
# anti join means that all entries in dupe.time will be removed, leaving only the first
suppressMessages(x3 <- x2 %>%
anti_join(dupe.time))
return(x3)
}
test <- fix_ZC_timestamp_duplication(df)
