mutate(Station = "S0") %>%
select(Tree, Station, Timestamp, everything())
} else{
old.dat2 <- old.dat
}
old.dat3 <- old.dat2 %>%
group_by(Station) %>%
nest() %>%
mutate(data = map(data, fix_duplicate_timestamps)) %>%
unnest(data) %>%
ungroup()
filename.in.L2 <- file.path("Microclimate_data_L2",
str_c(i, "_MC", "_L2.csv"))
if(file.exists(filename.in.L2)){
new.dat <- read_csv(file.path("Microclimate_data_L2",
str_c(i, "_MC_L2.csv")))
old.dat4 <- old.dat3 %>%
filter(Timestamp < min(new.dat$Timestamp, na.rm = T))
d <- bind_rows(old.dat4, new.dat)
} else {
d <- old.dat3
cat("no new data for: ", i, "\n")
}
d2 <- d %>%
distinct() %>%
arrange(Tree, Station, Timestamp)
write_csv(d2, file.path("Microclimate_data_L3",
str_c(i, "_MC", "_L3.csv")))
cat("saved data for: ", i, "\n")
}
# !!!! SLOW !!!!!
for(i in MC.vec){
d <- read_csv(file.path("Microclimate_data_L3", str_c(i, "_MC", "_L3.csv")))
## Remove bad data ---------------------------------------------------------
BDE <- bad.data.expanded %>%
filter(Tree == i)
d2 <- d %>%
pivot_longer(4:12, names_to = "Variable", values_to = "Value") %>%
left_join(BDE, by = c("Tree", "Station", "Variable", "Timestamp")) %>%
mutate(Value = ifelse(!is.na(Bad.data), NA, Value)) %>%
select(-Bad.data) %>%
distinct() %>%
pivot_wider(names_from = Variable, values_from = Value)
# These thresholds are determined in the lower section of the script
d3 <- d2 %>%
mutate(Temp = ifelse(Temp == 0, NA, Temp),
RH = ifelse(RH == 0, NA, RH),
Atmos_pressure = ifelse(Atmos_pressure == 0, NA, Atmos_pressure),
Atmos_pressure = ifelse(Atmos_pressure > 100, NA, Atmos_pressure),
Wetness = ifelse(Wetness > 2500, NA, Wetness))
# RH fixes ------------------------------------------------------------------
# Change all RH > 1 to 1, then nest the df for the adjustment functions
d3.nst <- d3 %>%
mutate(RH = ifelse(RH > 1, 1, RH)) %>%
mutate(Key = str_c(i, "_", Station)) %>%
group_by(Station) %>%
nest() %>%
ungroup()
# str(d3.nst, max.level = 1)
# x <- d3.nst$data[[1]]
# str(x, max.level = 2)
d4 <- d3.nst %>%
mutate(data = map(data, adjust_RH_maxes_global)) %>%
mutate(data = map(data, adjust_RH_maxes_local)) %>%
unnest(data) %>%
ungroup() %>%
select(-Key)
# Calculate variables -----------------------------------------------------
d5 <- d4 %>%
mutate(VPD = calculate_VPD(Temp, RH))
# Wetness adjustment ------------------------------------------------------
# mutate(Wetness = 1.54 * exp(0.0058 * LWS_Count))
# d6 <- d5 %>%
#   mutate(Count = log(Wetness/1.54)/0.0058)
#
# d.sum <- d6 %>%
#   group_by(Tree, Station) %>%
#   summarise(minimum = min(Count, na.rm = T))
#
# Save --------------------------------------------------------------------
write_csv(d5, file.path("Microclimate_data_L4",
str_c(i, "_MC", "_L4.csv")))
cat("saved data for: ", i, "\n")
}
library(needs)
needs(tidyverse, shiny, lubridate)
source("app_functions_MC.R")
options(readr.show_col_types = FALSE)
import.log <- read_csv(file.path("Microclimate_data_supporting",
"zl6_import_log.csv"))
max.date <- max(import.log$Last.import, na.rm = T)
zl6 <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database_long.csv"))
instruments <- read_csv(file.path("Microclimate_data_supporting", "Meter_instruments.csv"))
ui <- fluidPage(
titlePanel("Microclimate data portal"),
sidebarLayout(
sidebarPanel(
sliderInput("daterange",
label = h4("Select date range"),
min = ymd("2022-06-01"),
max = as_date(Sys.time()),
value = c(ymd("2022-06-01"), Sys.time())),
fluidRow(radioButtons("fixed.y", inline = T,
label = h4("Fix y-axis?"),
choices = c("No", "Coarse", "Fine"),
selected = "No")),
fluidRow(sliderInput("y.coarse",
label = h4("Select coarse y-axis range"),
min = 0,
max = 1500,
value = c(0, 1500))),
fluidRow(
column(6,
sliderInput("y.fine.min",
label = h4("Select fine y-axis min"),
min = 0,
max = 100,
value = 0,
step = 0.5)),
column(6,
sliderInput("y.fine.range",
label = h4("Select fine y-axis range"),
min = 0,
max = 20,
value = 0,
step = 0.5))),
fluidRow(
column(3,
radioButtons("tree",
label = h4("Select tree"),
choices = c("ET1", "ET2", "ET3", "ET4",
"ET5", "ET6", "ET7", "ET8",
"FB1", "FB2", "FB3", "FB4",
"FB5", "FB6", "FB7", "FB8",
"TV1", "TV2", "TV3", "TV4",
"ETP1", "ETP2", "FBP1", "FBP2", "TVP"),
selected = "ET1")),
column(3, offset = 1,
fluidRow(
checkboxGroupInput("station",
label = h4("Select Station"),
choices = c("S0", "S1", "S2", "S3",
"S4", "S5", "CS"),
selected = c("S0", "S1", "S2", "S3",
"S4", "S5", "CS")),
# radioButtons("station",
#              label = h4("Select Station"),
#              choices = c("S0", "S1", "S2", "S3",
#                          "S4", "S5", "CS"),
#              selected = c("S1")),
radioButtons("Variable",
label = h4("Select variable"),
choices = c("Solar", "Temp", "RH", "Atmos_pressure",
"VPD", "Wetness", "Wind_direction",
"Wind_speed", "Gust_speed", "Precipitation",
"Precip_max", "EpiMoisture", "EpiTemp",
"ECRN-100_Precipitation",
"ECRN-100_Precip_max"),
selected = "Solar"),
)),
column(3, offset = 1,
fluidRow(
radioButtons("Level",
label = h4("Select level"),
choices = c("L3", "L4"),
selected = "L4")),
fluidRow(
radioButtons("Time.res",
label = h4("Select time resolution"),
choices = c("15 Min", "Hourly", "Daily", "Weekly"),
selected = "15 Min")))),
titlePanel("Download options"),
fluidRow(
column(5,
radioButtons("Time.format",
label = h4("Select time format"),
choices = list("ISO", "Excel_ready"),
selected = "ISO")),
column(5,
radioButtons("All.variables",
label = h4("Download all variables?"),
choices = list("All", "Only_selected"),
selected = "Only_selected"))
),
downloadButton("downloadData", "Download")
),
mainPanel(
tabsetPanel(
type = "tabs",
tabPanel("Plot",
"Graph shows data until:",
verbatimTextOutput("max.date.out"),
plotOutput("plot",
click = "plot_click",
brush = "plot_brush"),
verbatimTextOutput("plot_clickinfo"),
plotOutput("plot_brushedpoints")),
tabPanel("Wiring", tableOutput("wiring1"), tableOutput("wiring2"),
tableOutput("wiring3"), tableOutput("wiring4")),
tabPanel("Data", tableOutput("data1"), tableOutput("data2")),
tabPanel("Summary", tableOutput("summary"))))
)
)
server <- function(input, output, session) {
dataInput <- reactive({
read_csv(file.path(str_c("Microclimate_data_", input$Level),
str_c(input$tree, "_MC_", input$Level, ".csv"))) %>%
filter(Tree == input$tree) %>%
filter(Timestamp >= as.POSIXct(input$daterange[1], tz = "UTC")  &
Timestamp <= as.POSIXct(input$daterange[2], tz = "UTC"))
})
dataInput2 <- reactive({
dataInput() %>%
filter(Station %in% input$station) %>%
pivot_longer(4:ncol(dataInput()),
names_to = "Variable", values_to = "Measure") %>%
filter(Variable == input$Variable)
})
dataInput3 <- reactive({
if(input$Time.res == "15 Min"){
dataInput2()
} else if(input$Time.res == "Hourly"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "hour"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()
} else if(input$Time.res == "Daily"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "day"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()
} else if(input$Time.res == "Weekly"){
dataInput2() %>%
group_by(Tree, Station, Timestamp = floor_date(Timestamp, "week"), Variable) %>%
summarise(across(where(is.numeric), ~mean(., na.rm = T))) %>%
ungroup()}
})
## Plots -------------------------------------------------------------------
output$plot <- renderPlot({
p <- ggplot(dataInput3()) +
geom_line(aes(x = Timestamp, y = Measure, color = Station)) +
theme_bw() +
theme(axis.title.x = element_blank()) +
theme(axis.title.x = element_blank(),
axis.text.x = element_text(size = 20),
axis.title.y = element_text(size = 24),
axis.text.y = element_text(size = 20),
plot.title = element_text(size = 24)) +
ggtitle(str_c(input$tree, "_", input$Variable))
if(input$fixed.y == "Coarse"){
p <- p +
ylim(input$y.coarse[1], input$y.coarse[2])
}
if(input$fixed.y == "Fine"){
p <- p +
ylim(input$y.fine.min, input$y.fine.min + input$y.fine.range)
}
p
})
output$plot_clickinfo <- renderPrint({
val <- nearPoints(dataInput3(), input$plot_click, maxpoints = 1)
unique(val$Timestamp)
})
output$plot_brushedpoints <- renderPlot({
dat <- brushedPoints(dataInput3(), input$plot_brush)
if (nrow(dat) == 0)
return()
ggplot(dat) +
geom_line(aes(x = Timestamp, y = Measure)) +
theme_bw() +
theme(axis.title.x = element_blank()) +
theme(axis.title.x = element_blank(),
axis.text.x = element_text(size = 20),
axis.title.y = element_text(size = 24),
axis.text.y = element_text(size = 20),
plot.title = element_text(size = 24))
})
## Data and tables --------------------------------------------------------
output$max.date.out <- renderText({
as.character(max(dataInput3()$Timestamp, na.rm = T))
})
locate.datalogger <- reactive({
inst <- instruments %>%
filter(Variable == input$Variable) %>%
pull(Instrument)
zl6 %>%
filter(Location == input$tree & Station %in% input$station &
Instrument == inst) %>%
select(MC.ID) %>%
distinct()
})
output$wiring1 <- renderTable({
instruments %>%
filter(Variable == input$Variable)
})
output$wiring2 <- renderTable({
locate.datalogger()
})
output$wiring3 <- renderTable({
zl6 %>%
filter(Location == input$tree & MC.ID %in% locate.datalogger()$MC.ID) %>%
select(-ZL.ID, -Location) %>%
mutate(Port = as.numeric(Port))
})
output$wiring4 <- renderTable({
inst <- instruments %>%
filter(Variable == input$Variable) %>%
pull(Instrument)
instruments %>%
filter(Instrument == inst)
})
data.for.summaries <- reactive({
dataInput3() %>%
mutate(Timestamp = as.character(Timestamp))
})
output$data1 <- renderTable({
head(data.for.summaries())
})
output$data2 <- renderTable({
tail(data.for.summaries())
})
output$summary <- renderTable({
summarise_MC(data.for.summaries())
})
## Download options --------------------------------------------------------
data.for.download <- reactive({
if(input$All.variables == "All"){
dataInput()
} else {
dataInput3()
}
})
data.for.download2 <- reactive({
if(input$Time.format == "Excel_ready"){
data.for.download() %>%
mutate(Timestamp = as.character(Timestamp))
} else {
data.for.download()
}
})
output$downloadData <- downloadHandler(
filename = function() {
str_c(str_c(input$tree,
str_sub(as.character(input$daterange[1]), start = 1, end = 10),
str_sub(as.character(input$daterange[2]), start = 1, end = 10),
sep = "_"),
".csv")
},
content <-  function(file) {
write_csv(data.for.download2(), file)
}
)
}
shinyApp(ui, server)
shinyApp(ui, server)
all.files <- list.files("Microclimate_data_L4", pattern = ".csv", full.names = TRUE)
# Trees
files.tree <- all.files[which(str_detect(all.files, "P") == F)]
library(needs)
needs(tidyverse, readxl)
source("3_Functions_Microclimate.R")
options(readr.show_col_types = FALSE)
theme_set(theme_bw())
all.files <- list.files("Microclimate_data_L4", pattern = ".csv", full.names = TRUE)
# Trees
files.tree <- all.files[which(str_detect(all.files, "P") == F)]
files.ground <- all.files[which(str_detect(all.files, "P") == T)]
d.tree <- lapply(files.tree, read_csv) %>%
bind_rows() %>%
filter(Timestamp >= ymd("2022-12-01") &
Timestamp < ymd("2023-12-01"))
View(d.tree)
d.tree <- lapply(files.tree, read_csv)
str(d.tree[[1]])
d.tree <- lapply(files.tree[1:2], read_csv) %>%
bind_rows()
View(d.tree)
d.tree <- lapply(files.tree[1:3], read_csv) %>%
bind_rows()
View(d.tree)
d.tree <- lapply(files.tree[1:4], read_csv) %>%
bind_rows()
d.tree <- lapply(files.tree[4:5], read_csv) %>%
bind_rows()
d.tree <- lapply(files.tree[4:6], read_csv) %>%
bind_rows()
d.tree <- lapply(files.tree[c(4,6)], read_csv) %>%
bind_rows()
d.tree <- lapply(files.tree[c(4,7)], read_csv) %>%
bind_rows()
d.tree <- lapply(files.tree[c(4,8)], read_csv) %>%
bind_rows()
d.tree <- lapply(files.tree[c(4,9)], read_csv) %>%
bind_rows()
library(needs)
needs(tidyverse, readxl)
source("3_Functions_Microclimate.R")
options(readr.show_col_types = FALSE)
zl6.db.long <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database_long.csv"))
zl6.db <- read_csv(file.path("Microclimate_data_supporting",
"zl6_database.csv"))
moved.instruments <- read_excel(file.path("Microclimate_data_supporting",
"zl6_moved_instruments.xlsx")) %>%
select(Tree, Station, Instrument, MC.old, MC.new, Timestamp) %>%
pivot_longer(4:5, names_to = "Tracking", values_to = "MC")
tree.vec <- c("ET5")
# tree.vec <- "ET7"
i <- "ET5"
d.nst <- MC_to_tree(i)
d.nst2 <- d.nst %>%
mutate(data = map(data, fix_duplicate_timestamps))
# !Only add row to moved_instruments if it was moved to new datalogger! Otherwise, just update the zl6_database_long sheet.
# Moving instrument to new datalogger causes a duplicated record with filler NAs
# This step checks to see if this happened in the last download cycle (estimated 45 days), then applies a function if needed
fix.needed <- moved.instruments %>%
filter(Tree == i) %>%
filter(Timestamp >= as_date(endDL) - days(45) & Timestamp <= as_date(endDL))
d.nst3 <- d.nst2
stations <- unique(d.nst3$Station)
d.list <- lapply(stations, MC_to_station, d.nested = d.nst3)
d.list2 <- lapply(d.list, remove_station_from_header)
d <- d.list2 %>%
bind_rows() %>%
select(-ATM22_temp, -ATM22_Xaxis,
-ATM22_Yaxis) %>%
arrange(Tree, Station, Timestamp)
View(d)
View(d)
MC_to_tree("ET5")
d <- MC_to_tree("ET5")
fix_duplicate_timestamps(d$data[[1]])
fix_duplicate_timestamps(d$data[[2]])
fix_duplicate_timestamps(d$data[[3]])
fix_duplicate_timestamps(d$data[[4]])
d2 <- fix_duplicate_timestamps(d$data[[4]])
# d <- MC_to_tree("ET5")
d2 <- d %>%
mutate(data = map(data, fix_duplicate_timestamps))
d.nst <- MC_to_tree(i)
d.nst2 <- d.nst %>%
mutate(data = map(data, fix_duplicate_timestamps))
# !Only add row to moved_instruments if it was moved to new datalogger! Otherwise, just update the zl6_database_long sheet.
# Moving instrument to new datalogger causes a duplicated record with filler NAs
# This step checks to see if this happened in the last download cycle (estimated 45 days), then applies a function if needed
# fix.needed <- moved.instruments %>%
#   filter(Tree == i) %>%
#   filter(Timestamp >= as_date(endDL) - days(45) & Timestamp <= as_date(endDL))
#
d.nst3 <- d.nst2
stations <- unique(d.nst3$Station)
d.list <- lapply(stations, MC_to_station, d.nested = d.nst3)
d.list2 <- lapply(d.list, remove_station_from_header)
d <- d.list2 %>%
bind_rows() %>%
select(-ATM22_temp, -ATM22_Xaxis,
-ATM22_Yaxis) %>%
arrange(Tree, Station, Timestamp)
View(d)
str(d.list2[[1]])
str(d.list2[[2]])
str(d.list2[[3]])
str(d.list2[[4]])
d3 <- MC_to_station(4, d2)
d3 <- MC_to_station(StationNum = "S3", d.nested = d2)
View(d3)
d3 <- MC_to_station(StationNum = "S2", d.nested = d2)
# Filters the output of "MC_to_tree" to an individual station and outputs the df with all variables
# StationNum: A station ID, such as "S1"; d.nested: A nested df output from "MC_to_tree"
StationNum <- "S2"
d.nested <- MC_to_tree("ET5")
nst <- d.nested %>%
filter(Station == StationNum) %>%
ungroup()
df <- reduce(nst$data, full_join, by = "Timestamp") %>%
mutate(Tree = unique(nst$Tree),
Station = unique(nst$Station)) %>%
select(Tree, Station, Timestamp, everything())
nst$data[[1]]
nst$data[[2]]
str(nst$data, max.level = 2)
nst$data[[1]]
str(nst, max.level = 2)
View(nst)
View(nst[[5]][[2]])
View(nst[[5]][[5]])
# When sensors get moved to a new datalogger, it adds a whole bunch ofleading NAs to new data and trailing NAs to old data if datalogger still installed. These then create duplicated timestamps when bound together
# d.nst: output from MC_to_tree, created in the first line of the for loop in Step 2
d.nst <- MC_to_tree("ET5")
remove_leading_NAs <- function(x, y){
x %>%
filter(floor_date(Timestamp, "days") > y)
}
remove_trailing_NAs <- function(x, y){
x %>%
filter(floor_date(Timestamp, "days") < y)
}
d <- d.nst %>%
left_join(moved.instruments, by = c("Tree", "Station", "Instrument", "MC"))
View(d)
d <- d.nst %>%
left_join(moved.instruments, by = c("Tree", "Station", "Instrument", "MC")) %>%
filter(!is.na(Timestamp)) %>%
mutate(data = ifelse(Tracking == "MC.new",
map2(data, Timestamp, remove_leading_NAs), data)) %>%
mutate(data = ifelse(Tracking == "MC.old",
map2(data, Timestamp, remove_trailing_NAs), data)) %>%
select(-Timestamp, -Tracking)
View(d)
View(d[[5]][[1]])
View(d[[5]][[2]])
